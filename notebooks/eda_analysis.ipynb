{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial News and Stock Price Integration Dataset - EDA\n",
    "## Nova Financial Solutions\n",
    "\n",
    "This notebook performs comprehensive Exploratory Data Analysis on the Financial News dataset.\n",
    "\n",
    "**Dataset Requirements:**\n",
    "- `headline`: The financial news headline\n",
    "- `url`: Link to the full article\n",
    "- `publisher`: Author or news source\n",
    "- `date`: Publication date and time (UTC-4 timezone)\n",
    "- `stock`: Stock ticker symbol (e.g., AAPL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Project root: C:\\Users\\HomePC\\Desktop\\Second\\Predicting-Price-Moves-with-News-Sentiment\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "project_root = Path().resolve().parent\n",
    "src_path = str(project_root / 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import all analysis modules\n",
    "from data_loader import DataLoader\n",
    "from eda_analyzer import EDAAnalyzer\n",
    "from topic_modeling import TopicModeler\n",
    "from publisher_analyzer import PublisherAnalyzer\n",
    "\n",
    "# Store in globals for easy access in other cells\n",
    "globals()['DataLoader'] = DataLoader\n",
    "globals()['EDAAnalyzer'] = EDAAnalyzer\n",
    "globals()['TopicModeler'] = TopicModeler\n",
    "globals()['PublisherAnalyzer'] = PublisherAnalyzer\n",
    "globals()['project_root'] = project_root\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(\"All modules are now available in this notebook session.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Preprocess Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATASET LOADING\n",
      "================================================================================\n",
      "Looking for dataset at: C:\\Users\\HomePC\\Desktop\\Second\\Predicting-Price-Moves-with-News-Sentiment\\data\\raw_analyst_ratings.csv\n",
      "\n",
      "✓ Dataset file found!\n",
      "Loading dataset...\n",
      "Removed 1351341 rows with missing critical data\n",
      "\n",
      "✓ Loaded 55,987 articles\n",
      "✓ Date range: 2011-04-28 01:01:48+00:00 to 2020-06-11 21:12:35+00:00\n",
      "✓ Unique publishers: 225\n",
      "✓ Unique stocks: 6204\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>headline</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>date_only</th>\n",
       "      <th>headline_length</th>\n",
       "      <th>headline_word_count</th>\n",
       "      <th>publisher_domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Stocks That Hit 52-Week Highs On Friday</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16190091/s...</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>2020-06-05 14:30:54+00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2020-06-05</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Stocks That Hit 52-Week Highs On Wednesday</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16170189/s...</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>2020-06-03 14:45:20+00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2020-06-03</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>71 Biggest Movers From Friday</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16103463/7...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-05-26 08:30:07+00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>Lisa Levin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>46 Stocks Moving In Friday's Mid-Day Session</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16095921/4...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-05-22 16:45:06+00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2020-05-22</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>Lisa Levin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>B of A Securities Maintains Neutral on Agilent...</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16095304/b...</td>\n",
       "      <td>Vick Meyer</td>\n",
       "      <td>2020-05-22 15:38:59+00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2020-05-22</td>\n",
       "      <td>87</td>\n",
       "      <td>14</td>\n",
       "      <td>Vick Meyer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           headline  \\\n",
       "0           0            Stocks That Hit 52-Week Highs On Friday   \n",
       "1           1         Stocks That Hit 52-Week Highs On Wednesday   \n",
       "2           2                      71 Biggest Movers From Friday   \n",
       "3           3       46 Stocks Moving In Friday's Mid-Day Session   \n",
       "4           4  B of A Securities Maintains Neutral on Agilent...   \n",
       "\n",
       "                                                 url          publisher  \\\n",
       "0  https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
       "1  https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
       "2  https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
       "3  https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
       "4  https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
       "\n",
       "                       date stock    year  month   day day_of_week  hour  \\\n",
       "0 2020-06-05 14:30:54+00:00     A  2020.0    6.0   5.0      Friday  14.0   \n",
       "1 2020-06-03 14:45:20+00:00     A  2020.0    6.0   3.0   Wednesday  14.0   \n",
       "2 2020-05-26 08:30:07+00:00     A  2020.0    5.0  26.0     Tuesday   8.0   \n",
       "3 2020-05-22 16:45:06+00:00     A  2020.0    5.0  22.0      Friday  16.0   \n",
       "4 2020-05-22 15:38:59+00:00     A  2020.0    5.0  22.0      Friday  15.0   \n",
       "\n",
       "    date_only  headline_length  headline_word_count   publisher_domain  \n",
       "0  2020-06-05               39                    7  Benzinga Insights  \n",
       "1  2020-06-03               42                    7  Benzinga Insights  \n",
       "2  2020-05-26               29                    5         Lisa Levin  \n",
       "3  2020-05-22               44                    7         Lisa Levin  \n",
       "4  2020-05-22               87                   14         Vick Meyer  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update this path to your dataset location\n",
    "# You can use a relative path from the project root or an absolute path\n",
    "# Default: looks for file in the project's data/ folder\n",
    "DATA_PATH = \"data/raw_analyst_ratings.csv\"\n",
    "\n",
    "# Ensure imports and project_root are available (works even if cells are run out of order)\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Define project_root (notebook is in notebooks/ folder, so parent is project root)\n",
    "project_root = Path().resolve().parent\n",
    "print(f\"Project root: {project_root}\")\n",
    "\n",
    "# Add src to path if not already added\n",
    "src_path = str(project_root / 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "    print(f\"Added to sys.path: {src_path}\")\n",
    "else:\n",
    "    print(f\"Path already in sys.path: {src_path}\")\n",
    "\n",
    "# Verify src directory exists\n",
    "src_dir = project_root / 'src'\n",
    "data_loader_file = src_dir / 'data_loader.py'\n",
    "print(f\"Looking for data_loader.py at: {data_loader_file}\")\n",
    "\n",
    "if not src_dir.exists():\n",
    "    raise FileNotFoundError(f\"Source directory not found at {src_dir}. Please ensure you're running from the correct location.\")\n",
    "\n",
    "if not data_loader_file.exists():\n",
    "    raise FileNotFoundError(f\"data_loader.py not found at {data_loader_file}. Please ensure the file exists.\")\n",
    "\n",
    "# Import DataLoader\n",
    "print(\"Importing DataLoader...\")\n",
    "try:\n",
    "    from data_loader import DataLoader\n",
    "    print(\"✓ DataLoader imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Import failed. sys.path: {sys.path[:3]}...\")  # Show first 3 paths\n",
    "    raise ImportError(\n",
    "        f\"Failed to import DataLoader from {src_path}. \"\n",
    "        f\"Please ensure the src/data_loader.py file exists. \"\n",
    "        f\"Error: {e}\"\n",
    "    )\n",
    "\n",
    "# Convert to absolute path for better reliability\n",
    "# Handle both relative paths (from project root) and absolute paths\n",
    "if Path(DATA_PATH).is_absolute():\n",
    "    data_path_abs = Path(DATA_PATH)\n",
    "else:\n",
    "    data_path_abs = (project_root / DATA_PATH).resolve()\n",
    "\n",
    "# Check if file exists\n",
    "print(\"=\" * 80)\n",
    "print(\"DATASET LOADING\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Looking for dataset at: {data_path_abs}\")\n",
    "\n",
    "if not data_path_abs.exists():\n",
    "    print(\"\\n❌ ERROR: Dataset file not found!\")\n",
    "    print(f\"\\nLooking for file at: {data_path_abs}\")\n",
    "    print(f\"\\nPlease do ONE of the following:\")\n",
    "    print(f\"\\n1. Place your dataset CSV file at:\")\n",
    "    print(f\"   {data_path_abs}\")\n",
    "    print(f\"\\n2. Or update the DATA_PATH variable above to point to your dataset.\")\n",
    "    print(f\"   For example:\")\n",
    "    print(f\"   DATA_PATH = 'data/your_file.csv'  # relative to project root\")\n",
    "    print(f\"   DATA_PATH = 'C:/path/to/your/file.csv'  # absolute path\")\n",
    "    \n",
    "    # Check if data directory exists\n",
    "    data_dir = project_root / \"data\"\n",
    "    if data_dir.exists():\n",
    "        print(f\"\\n✓ Found data directory at: {data_dir}\")\n",
    "        print(f\"  Files in data directory:\")\n",
    "        try:\n",
    "            files = list(data_dir.glob(\"*.csv\"))\n",
    "            if files:\n",
    "                for f in files[:5]:  # Show first 5 CSV files\n",
    "                    print(f\"    - {f.name}\")\n",
    "                if len(files) > 5:\n",
    "                    print(f\"    ... and {len(files) - 5} more CSV files\")\n",
    "            else:\n",
    "                print(f\"    (no CSV files found)\")\n",
    "        except:\n",
    "            pass\n",
    "    else:\n",
    "        print(f\"\\n⚠ Data directory not found at: {data_dir}\")\n",
    "        print(f\"  You may need to create it first.\")\n",
    "    \n",
    "    print(f\"\\nExpected columns in the dataset:\")\n",
    "    print(\"  - headline: The financial news headline\")\n",
    "    print(\"  - url: Link to the full article\")\n",
    "    print(\"  - publisher: Author or news source\")\n",
    "    print(\"  - date: Publication date and time (UTC-4 timezone)\")\n",
    "    print(\"  - stock: Stock ticker symbol (e.g., AAPL)\")\n",
    "    \n",
    "    raise FileNotFoundError(f\"Dataset not found at {data_path_abs}\\nPlease place your dataset CSV file at the specified location or update DATA_PATH.\")\n",
    "\n",
    "# Load data\n",
    "print(\"\\n✓ Dataset file found!\")\n",
    "print(\"Loading dataset...\")\n",
    "loader = DataLoader(str(data_path_abs))\n",
    "df = loader.load_data()\n",
    "df = loader.preprocess_data()\n",
    "\n",
    "print(f\"\\n✓ Loaded {len(df):,} articles\")\n",
    "print(f\"✓ Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"✓ Unique publishers: {df['publisher'].nunique()}\")\n",
    "print(f\"✓ Unique stocks: {df['stock'].nunique()}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Descriptive Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DESCRIPTIVE STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Dataset Overview:\n",
      "  Total Articles: 55,987\n",
      "  Unique Publishers: 225\n",
      "  Unique Stocks: 6204\n",
      "  Date Range: 2011-04-28 01:01:48+00:00 to 2020-06-11 21:12:35+00:00\n",
      "\n",
      "Headline Length Statistics (Characters):\n",
      "  Min: 12\n",
      "  Max: 512\n",
      "  Mean: 80.02\n",
      "  Median: 63.00\n",
      "  Std Dev: 56.13\n",
      "  Q25: 42.00\n",
      "  Q75: 91.00\n",
      "\n",
      "Headline Word Count Statistics:\n",
      "  Min: 2\n",
      "  Max: 77\n",
      "  Mean: 12.44\n",
      "  Median: 10.00\n",
      "  Std Dev: 8.46\n"
     ]
    }
   ],
   "source": [
    "# Ensure imports are available (works even if cells are run out of order)\n",
    "try:\n",
    "    from eda_analyzer import EDAAnalyzer\n",
    "except ImportError:\n",
    "    import sys\n",
    "    from pathlib import Path\n",
    "    project_root = Path().resolve().parent\n",
    "    src_path = str(project_root / 'src')\n",
    "    if src_path not in sys.path:\n",
    "        sys.path.insert(0, src_path)\n",
    "    from eda_analyzer import EDAAnalyzer\n",
    "\n",
    "# Initialize EDA analyzer\n",
    "eda = EDAAnalyzer(df, \"../output\")\n",
    "stats = eda.compute_descriptive_stats()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DESCRIPTIVE STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nDataset Overview:\")\n",
    "print(f\"  Total Articles: {stats['total_articles']:,}\")\n",
    "print(f\"  Unique Publishers: {stats['unique_publishers']}\")\n",
    "print(f\"  Unique Stocks: {stats['unique_stocks']}\")\n",
    "print(f\"  Date Range: {stats['date_range']['start']} to {stats['date_range']['end']}\")\n",
    "\n",
    "print(f\"\\nHeadline Length Statistics (Characters):\")\n",
    "print(f\"  Min: {stats['headline_length']['min']}\")\n",
    "print(f\"  Max: {stats['headline_length']['max']}\")\n",
    "print(f\"  Mean: {stats['headline_length']['mean']:.2f}\")\n",
    "print(f\"  Median: {stats['headline_length']['median']:.2f}\")\n",
    "print(f\"  Std Dev: {stats['headline_length']['std']:.2f}\")\n",
    "print(f\"  Q25: {stats['headline_length']['q25']:.2f}\")\n",
    "print(f\"  Q75: {stats['headline_length']['q75']:.2f}\")\n",
    "\n",
    "print(f\"\\nHeadline Word Count Statistics:\")\n",
    "print(f\"  Min: {stats['headline_word_count']['min']}\")\n",
    "print(f\"  Max: {stats['headline_word_count']['max']}\")\n",
    "print(f\"  Mean: {stats['headline_word_count']['mean']:.2f}\")\n",
    "print(f\"  Median: {stats['headline_word_count']['median']:.2f}\")\n",
    "print(f\"  Std Dev: {stats['headline_word_count']['std']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating headline length distribution visualizations...\n"
     ]
    }
   ],
   "source": [
    "# Ensure matplotlib is imported\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize headline length distribution\n",
    "print(\"Generating headline length distribution visualizations...\")\n",
    "eda.plot_headline_length_distribution(save=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Top Publishers Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TOP 10 PUBLISHERS BY ARTICLE COUNT\n",
      "================================================================================\n",
      "        publisher  article_count  unique_stocks             first_article              last_article\n",
      "Benzinga Newsdesk          14750           3771 2016-06-23 12:56:09+00:00 2020-06-11 21:11:20+00:00\n",
      "       Lisa Levin          12408           3646 2011-06-07 13:49:32+00:00 2020-06-11 16:19:17+00:00\n",
      "    ETF Professor           4362           1010 2011-04-28 01:01:48+00:00 2020-06-11 19:25:36+00:00\n",
      "    Paul Quintaro           4212           1242 2011-05-17 14:06:30+00:00 2018-05-31 19:49:22+00:00\n",
      "Benzinga Newsdesk           3177            956 2020-05-12 16:00:37+00:00 2020-06-11 18:26:26+00:00\n",
      "Benzinga Insights           2332           1202 2020-03-24 15:35:03+00:00 2020-06-11 20:24:41+00:00\n",
      "       Vick Meyer           2128           1228 2018-02-06 13:46:03+00:00 2020-06-03 14:08:51+00:00\n",
      "    Charles Gross           1790           1023 2011-11-30 12:34:52+00:00 2020-06-11 15:08:26+00:00\n",
      "       Hal Lindon           1470            844 2013-06-17 12:15:40+00:00 2019-07-11 14:36:51+00:00\n",
      "Benzinga_Newsdesk           1239            913 2018-07-16 19:12:17+00:00 2020-05-29 15:40:09+00:00\n"
     ]
    }
   ],
   "source": [
    "# Analyze top publishers\n",
    "top_publishers = eda.analyze_top_publishers(10)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TOP 10 PUBLISHERS BY ARTICLE COUNT\")\n",
    "print(\"=\" * 80)\n",
    "print(top_publishers.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top publishers\n",
    "eda.plot_top_publishers(10, save=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Publication Frequency Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PUBLICATION FREQUENCY INSIGHTS\n",
      "================================================================================\n",
      "\n",
      "Most Active Day of Week: Thursday (12712 articles)\n",
      "Most Active Month: May (11364 articles)\n",
      "Peak Hour: 14:00 (7669 articles)\n"
     ]
    }
   ],
   "source": [
    "# Analyze publication frequency\n",
    "freq_stats = eda.analyze_publication_frequency()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PUBLICATION FREQUENCY INSIGHTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Most active day\n",
    "max_day = max(freq_stats['by_day'].items(), key=lambda x: x[1])\n",
    "print(f\"\\nMost Active Day of Week: {max_day[0]} ({max_day[1]} articles)\")\n",
    "\n",
    "# Most active month\n",
    "max_month = max(freq_stats['by_month'].items(), key=lambda x: x[1])\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "               'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "print(f\"Most Active Month: {month_names[max_month[0]-1]} ({max_month[1]} articles)\")\n",
    "\n",
    "# Peak hour\n",
    "max_hour = max(freq_stats['by_hour'].items(), key=lambda x: x[1])\n",
    "print(f\"Peak Hour: {max_hour[0]:02d}:00 ({max_hour[1]} articles)\")\n",
    "\n",
    "# Visualize\n",
    "eda.plot_publication_frequency(save=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 News Activity Spikes Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "NEWS ACTIVITY SPIKES (>2σ above mean)\n",
      "================================================================================\n",
      "Total Spikes Detected: 51\n",
      "\n",
      "Top 10 Spikes:\n",
      "      date  article_count  deviation_from_mean  std_deviation\n",
      "2020-03-12            973           950.623102      13.883485\n",
      "2020-06-05            932           909.623102      13.284696\n",
      "2020-06-10            807           784.623102      11.459119\n",
      "2020-06-09            803           780.623102      11.400700\n",
      "2020-06-08            765           742.623102      10.845725\n",
      "2020-05-07            751           728.623102      10.641260\n",
      "2020-06-03            720           697.623102      10.188517\n",
      "2020-03-19            630           607.623102       8.874102\n",
      "2020-05-26            628           605.623102       8.844893\n",
      "2020-05-13            549           526.623102       7.691128\n"
     ]
    }
   ],
   "source": [
    "# Detect news spikes (articles > 2 standard deviations above mean)\n",
    "spikes = eda.detect_news_spikes(threshold_std=2.0)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"NEWS ACTIVITY SPIKES (>2σ above mean)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total Spikes Detected: {len(spikes)}\")\n",
    "\n",
    "if len(spikes) > 0:\n",
    "    print(\"\\nTop 10 Spikes:\")\n",
    "    print(spikes.head(10).to_string(index=False))\n",
    "    \n",
    "    # Visualize spikes\n",
    "    eda.plot_news_spikes(threshold_std=2.0, save=False)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No significant spikes detected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Topic Modeling - Frequent Keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frequent keywords...\n",
      "Preprocessing headlines...\n",
      "Creating dictionary...\n",
      "Creating corpus...\n",
      "Corpus prepared: 55987 documents, 6633 unique terms\n",
      "================================================================================\n",
      "TOP 50 FREQUENT KEYWORDS\n",
      "================================================================================\n",
      "  keyword  frequency  percentage\n",
      "     week       9090    2.211878\n",
      "      hit       5925    1.441736\n",
      "      low       5660    1.377253\n",
      "      eps       5530    1.345620\n",
      "   target       4695    1.142439\n",
      "  several       4650    1.131489\n",
      "     sale       4616    1.123215\n",
      "    lower       4503    1.095719\n",
      "      etf       4497    1.094259\n",
      "   higher       4269    1.038780\n",
      " estimate       4090    0.995223\n",
      "  session       3486    0.848252\n",
      "maintains       3266    0.794719\n",
      "     high       3090    0.751893\n",
      "yesterday       3068    0.746539\n",
      " thursday       2927    0.712230\n",
      "   moving       2867    0.697630\n",
      "     amid       2672    0.650180\n",
      "   friday       2634    0.640934\n",
      "following       2525    0.614411\n"
     ]
    }
   ],
   "source": [
    "# Initialize topic modeler\n",
    "topic_modeler = TopicModeler(df, \"../output\")\n",
    "\n",
    "# Extract frequent keywords\n",
    "print(\"Extracting frequent keywords...\")\n",
    "keywords_df = topic_modeler.extract_frequent_keywords(50)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TOP 50 FREQUENT KEYWORDS\")\n",
    "print(\"=\" * 80)\n",
    "print(keywords_df.head(20).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize frequent keywords\n",
    "topic_modeler.plot_frequent_keywords(30, save=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Topic Modeling - LDA (Latent Dirichlet Allocation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRAINING LDA MODEL\n",
      "================================================================================\n",
      "This may take a few minutes...\n",
      "Training LDA model with 10 topics...\n",
      "LDA model trained successfully!\n",
      "\n",
      "✓ LDA Model Trained Successfully!\n",
      "\n",
      "Extracted Topics:\n",
      "================================================================================\n",
      "\n",
      "Topic_0:\n",
      "  Top words: several\" , higher\" , reopening\" , optimism\" , following\" , amid\" , economy\" , economic\" , equity\" , strong\n",
      "\n",
      "Topic_1:\n",
      "  Top words: etf\" , set\" , week\" , low\" , yesterday\" , dividend\" , october\" , watch\" , september\" , nov\n",
      "\n",
      "Topic_2:\n",
      "  Top words: target\" , maintains\" , raise\" , lower\" , buy\" , downgrade\" , neutral\" , morgan\" , outperform\" , announces\n",
      "\n",
      "Topic_3:\n",
      "  Top words: week\" , hit\" , eps\" , sale\" , estimate\" , low\" , high\" , yoy\" , thursday\" , beat\n",
      "\n",
      "Topic_4:\n",
      "  Top words: several\" , higher\" , lower\" , amid\" , coronavirus\" , economic\" , following\" , state\" , sector\" , oil\n",
      "\n",
      "Topic_5:\n",
      "  Top words: biggest\" , mover\" , yesterday\" , update\" , friday\" , midafternoon\" , midday\" , merger\" , spike\" , acquisition\n",
      "\n",
      "Topic_6:\n",
      "  Top words: earnings\" , update\" , lower\" , second\" , higher\" , wave\" , case\" , midmorning\" , leading\" , open\n",
      "\n",
      "Topic_7:\n",
      "  Top words: top\" , benzingas\" , downgrade\" , upgrade\" , biotech\" , daily\" , pulse\" , industry\" , fda\" , resume\n",
      "\n",
      "Topic_8:\n",
      "  Top words: session\" , moving\" , midday\" , premarket\" , earnings\" , wednesday\" , scheduled\" , tuesday\" , monday\" , oil\n",
      "\n",
      "Topic_9:\n",
      "  Top words: announces\" , cash\" , energy\" , capital\" , inc\" , group\" , deal\" , agreement\" , fund\" , change\n"
     ]
    }
   ],
   "source": [
    "# Train LDA model\n",
    "print(\"=\" * 80)\n",
    "print(\"TRAINING LDA MODEL\")\n",
    "print(\"=\" * 80)\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "lda_model = topic_modeler.train_lda(num_topics=10, passes=10)\n",
    "lda_topics = topic_modeler.get_lda_topics(num_words=10)\n",
    "\n",
    "print(\"\\n✓ LDA Model Trained Successfully!\")\n",
    "print(\"\\nExtracted Topics:\")\n",
    "print(\"=\" * 80)\n",
    "for topic_name, topic_data in lda_topics.items():\n",
    "    print(f\"\\n{topic_name}:\")\n",
    "    print(f\"  Top words: {', '.join(topic_data['top_words'][:10])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize LDA topics\n",
    "topic_modeler.plot_lda_topics(num_words=10, save=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating interactive LDA visualization...\n",
      "Creating LDA visualization...\n",
      "⚠ Could not create interactive visualization: [Errno 2] No such file or directory: '../output/lda_visualization.html'\n"
     ]
    }
   ],
   "source": [
    "# Create interactive LDA visualization (optional)\n",
    "try:\n",
    "    print(\"Creating interactive LDA visualization...\")\n",
    "    vis = topic_modeler.create_lda_visualization(save=True)\n",
    "    print(\"✓ Interactive visualization saved to output/lda_visualization.html\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Could not create interactive visualization: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Topic Modeling - BERTopic (Optional, Advanced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRAINING BERTOPIC MODEL (Optional)\n",
      "================================================================================\n",
      "This may take several minutes...\n",
      "Training BERTopic model...\n",
      "This may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 19:14:22,137 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1fbdf63e20b4d139a016f9d6f5afde2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e269795998c45ba8d5517fa59f8e30e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90402c1caed248b29ab68d9ab74194cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b9ab643d1a49a0ad5e0084dbce1ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "598acb38ba2742a68fe6dce0aed54a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e8cace66e94e7486f89e484e18819f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3822e9bd1ce14b93bbf7f5608dcaffe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6cdbe6ea034784b4380d940187df2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed698772125345b48294aedc6c19297a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7648a8c76d4b0fbfb38f1b68a742e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a5e1e225c9f4624abe7cec2ab98330e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7daa622b32401eb5e68e5df5a8bdf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 19:28:35,755 - BERTopic - Embedding - Completed ✓\n",
      "2025-11-23 19:28:35,761 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-11-23 19:32:39,189 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-11-23 19:32:39,275 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-11-23 19:32:55,194 - BERTopic - Cluster - Completed ✓\n",
      "2025-11-23 19:32:55,357 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2025-11-23 19:33:00,488 - BERTopic - Representation - Completed ✓\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTopic model trained successfully!\n",
      "\n",
      "✓ BERTopic Model Trained Successfully!\n",
      "✓ Found 996 topics\n",
      "Error creating BERTopic visualizations: [Errno 2] No such file or directory: '..\\\\output\\\\bertopic_topics.html'\n",
      "✓ BERTopic visualizations saved\n",
      "\n",
      "Sample BERTopic Topics:\n",
      "\n",
      "Topic_-1:\n",
      "  Count: 12109\n",
      "  Top words: reports, yoy, eps, vs, sales, est, deal, q2, cash, q3\n",
      "\n",
      "Topic_0:\n",
      "  Count: 1764\n",
      "  Top words: thursday, lows, hit, that, 52week, stocks, on, , , \n",
      "\n",
      "Topic_1:\n",
      "  Count: 882\n",
      "  Top words: estimate, beat, beats, miss, misses, adj, sales, eps, q1, inline\n",
      "\n",
      "Topic_2:\n",
      "  Count: 716\n",
      "  Top words: friday, lows, hit, that, 52week, stocks, on, breach, managed, to\n",
      "\n",
      "Topic_3:\n",
      "  Count: 540\n",
      "  Top words: friday, highs, hit, that, 52week, stocks, on, , , \n"
     ]
    }
   ],
   "source": [
    "# Train BERTopic model (optional - may take longer)\n",
    "print(\"=\" * 80)\n",
    "print(\"TRAINING BERTOPIC MODEL (Optional)\")\n",
    "print(\"=\" * 80)\n",
    "print(\"This may take several minutes...\")\n",
    "\n",
    "try:\n",
    "    bertopic_model = topic_modeler.train_bertopic(min_topic_size=10)\n",
    "    \n",
    "    if bertopic_model:\n",
    "        bertopic_topics = topic_modeler.get_bertopic_topics()\n",
    "        print(\"\\n✓ BERTopic Model Trained Successfully!\")\n",
    "        print(f\"✓ Found {len(bertopic_topics)} topics\")\n",
    "        \n",
    "        # Visualize\n",
    "        topic_modeler.plot_bertopic_topics(save=True)\n",
    "        print(\"✓ BERTopic visualizations saved\")\n",
    "        \n",
    "        # Show sample topics\n",
    "        print(\"\\nSample BERTopic Topics:\")\n",
    "        for i, (topic_name, topic_data) in enumerate(list(bertopic_topics.items())[:5]):\n",
    "            print(f\"\\n{topic_name}:\")\n",
    "            print(f\"  Count: {topic_data['count']}\")\n",
    "            print(f\"  Top words: {', '.join(topic_data['words'][:10])}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ BERTopic training failed or not available: {e}\")\n",
    "    print(\"Continuing with LDA results only...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Assign Topics to Articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TOPIC ASSIGNMENT SUMMARY\n",
      "================================================================================\n",
      "Total articles with topic assignments: 55987\n",
      "\n",
      "Topic distribution:\n",
      "lda_topic\n",
      "0     2222\n",
      "1     7015\n",
      "2     6610\n",
      "3    11977\n",
      "4     3562\n",
      "5     5209\n",
      "6     3532\n",
      "7     4396\n",
      "8     4726\n",
      "9     6738\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample articles with topic assignments:\n",
      "                                                                                                                headline stock               publisher  lda_topic\n",
      "                                                                                 Stocks That Hit 52-Week Highs On Friday     A       Benzinga Insights          3\n",
      "                                                                              Stocks That Hit 52-Week Highs On Wednesday     A       Benzinga Insights          3\n",
      "                                                                                           71 Biggest Movers From Friday     A              Lisa Levin          5\n",
      "                                                                            46 Stocks Moving In Friday's Mid-Day Session     A              Lisa Levin          8\n",
      "                                 B of A Securities Maintains Neutral on Agilent Technologies, Raises Price Target to $88     A              Vick Meyer          2\n",
      "                                                 CFRA Maintains Hold on Agilent Technologies, Lowers Price Target to $85     A vishwanath@benzinga.com          2\n",
      "                                               UBS Maintains Neutral on Agilent Technologies, Raises Price Target to $87     A vishwanath@benzinga.com          2\n",
      "Agilent Technologies shares are trading higher after the company reported better-than-expected Q2 EPS and sales results.     A       Benzinga Newsdesk          4\n",
      "                                    Wells Fargo Maintains Overweight on Agilent Technologies, Raises Price Target to $95     A vishwanath@benzinga.com          2\n",
      "                                                                              10 Biggest Price Target Changes For Friday     A              Lisa Levin          5\n"
     ]
    }
   ],
   "source": [
    "# Assign LDA topics to articles\n",
    "df_with_topics = topic_modeler.assign_topics_to_articles(method='lda')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TOPIC ASSIGNMENT SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total articles with topic assignments: {len(df_with_topics)}\")\n",
    "print(\"\\nTopic distribution:\")\n",
    "print(df_with_topics['lda_topic'].value_counts().sort_index())\n",
    "\n",
    "# Show sample articles with topics\n",
    "print(\"\\nSample articles with topic assignments:\")\n",
    "print(df_with_topics[['headline', 'stock', 'publisher', 'lda_topic']].head(10).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Publisher Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PUBLISHER RANKINGS\n",
      "================================================================================\n",
      "              publisher  article_count  unique_stocks  avg_headline_length  std_headline_length             first_article              last_article  rank\n",
      "      Benzinga Newsdesk          14750           3771            97.485288            52.961824 2016-06-23 12:56:09+00:00 2020-06-11 21:11:20+00:00     1\n",
      "             Lisa Levin          12408           3646            44.391441            16.313968 2011-06-07 13:49:32+00:00 2020-06-11 16:19:17+00:00     2\n",
      "          ETF Professor           4362           1010            44.016735            10.909750 2011-04-28 01:01:48+00:00 2020-06-11 19:25:36+00:00     3\n",
      "          Paul Quintaro           4212           1242            84.106600            36.620906 2011-05-17 14:06:30+00:00 2018-05-31 19:49:22+00:00     4\n",
      "      Benzinga Newsdesk           3177            956           226.071766            66.098087 2020-05-12 16:00:37+00:00 2020-06-11 18:26:26+00:00     5\n",
      "      Benzinga Insights           2332           1202            45.597770            11.951976 2020-03-24 15:35:03+00:00 2020-06-11 20:24:41+00:00     6\n",
      "             Vick Meyer           2128           1228            75.748120            13.917903 2018-02-06 13:46:03+00:00 2020-06-03 14:08:51+00:00     7\n",
      "          Charles Gross           1790           1023            81.058101            37.097668 2011-11-30 12:34:52+00:00 2020-06-11 15:08:26+00:00     8\n",
      "             Hal Lindon           1470            844            85.782993            39.654187 2013-06-17 12:15:40+00:00 2019-07-11 14:36:51+00:00     9\n",
      "      Benzinga_Newsdesk           1239            913            83.262308            33.073983 2018-07-16 19:12:17+00:00 2020-05-29 15:40:09+00:00    10\n",
      "           Eddie Staley           1003            585            75.717846            32.269065 2011-07-11 16:15:45+00:00 2018-07-18 20:07:22+00:00    11\n",
      "vishwanath@benzinga.com            924            653            77.762987             9.543258 2020-04-07 14:58:11+00:00 2020-06-01 09:11:01+00:00    12\n",
      "       Shanthi Rexaline            887            428           102.629087            30.629088 2016-09-23 18:32:12+00:00 2020-06-11 14:37:56+00:00    13\n",
      "          Monica Gerson            611            370            50.785597            22.838956 2011-05-16 12:47:57+00:00 2017-09-29 12:30:45+00:00    14\n",
      "           Wayne Duggan            465            337            56.926882            17.608134 2014-12-16 17:00:57+00:00 2020-06-10 17:22:00+00:00    15\n"
     ]
    }
   ],
   "source": [
    "# Initialize publisher analyzer\n",
    "publisher_analyzer = PublisherAnalyzer(df, \"../output\")\n",
    "\n",
    "# Rank publishers\n",
    "rankings = publisher_analyzer.rank_publishers()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PUBLISHER RANKINGS\")\n",
    "print(\"=\" * 80)\n",
    "print(rankings.head(15).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize publisher analysis\n",
    "publisher_analyzer.plot_publisher_analysis(top_n=10, save=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Publisher Domain Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PUBLISHER DOMAIN ANALYSIS\n",
      "================================================================================\n",
      "Total unique domains: 4\n",
      "\n",
      "Top domains by article count:\n",
      "                publisher       domain  article_count\n",
      "  vishwanath@benzinga.com benzinga.com            924\n",
      "        luke@benzinga.com benzinga.com            271\n",
      "bret.kenwell@benzinga.com benzinga.com              1\n",
      "vivek.proactive@gmail.com    gmail.com              3\n"
     ]
    }
   ],
   "source": [
    "# Extract publisher domains\n",
    "domains = publisher_analyzer.extract_publisher_domains()\n",
    "\n",
    "if len(domains) > 0:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"PUBLISHER DOMAIN ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Total unique domains: {len(domains)}\")\n",
    "    print(\"\\nTop domains by article count:\")\n",
    "    print(domains.head(10).to_string(index=False))\n",
    "else:\n",
    "    print(\"No email-like publisher values found. Using publisher names directly.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Topic Preferences by Publisher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TOPIC PREFERENCES BY PUBLISHER\n",
      "================================================================================\n",
      "Percentage of articles mentioning each topic category:\n",
      "        publisher  total_articles  earnings_mentions  earnings_percentage  mergers_mentions  mergers_percentage  fda_approval_mentions  fda_approval_percentage  price_target_mentions  price_target_percentage  product_launch_mentions  product_launch_percentage  partnership_mentions  partnership_percentage  regulation_mentions  regulation_percentage  market_movement_mentions  market_movement_percentage\n",
      "Benzinga Newsdesk           14750               4737            32.115254               748            5.071186                    787                 5.335593                   2201                14.922034                     1473                   9.986441                   864                5.857627                  661               4.481356                      3027                   20.522034\n",
      "       Lisa Levin           12408                987             7.954545               147            1.184720                     40                 0.322373                   1553                12.516119                       12                   0.096712                    20                0.161186                    6               0.048356                       327                    2.635397\n",
      "    ETF Professor            4362                 97             2.223751                45            1.031637                     16                 0.366804                     88                 2.017423                       64                   1.467217                    19                0.435580                  136               3.117836                       156                    3.576341\n",
      "    Paul Quintaro            4212               1266            30.056980               740           17.568851                    169                 4.012346                    670                15.906933                      550                  13.057930                   543               12.891738                  182               4.320988                        91                    2.160494\n",
      "Benzinga Newsdesk            3177                336            10.576015                 0            0.000000                    427                13.440353                    170                 5.350960                      203                   6.389676                     0                0.000000                  949              29.870947                      3878                  122.064841\n",
      "Benzinga Insights            2332                416            17.838765                 0            0.000000                     83                 3.559177                    218                 9.348199                        3                   0.128645                     8                0.343053                    1               0.042882                         0                    0.000000\n",
      "       Vick Meyer            2128                  2             0.093985                 0            0.000000                     10                 0.469925                   4565               214.520677                      359                  16.870301                    70                3.289474                  144               6.766917                         0                    0.000000\n",
      "    Charles Gross            1790                154             8.603352               267           14.916201                     60                 3.351955                     87                 4.860335                      239                  13.351955                   208               11.620112                   33               1.843575                        41                    2.290503\n",
      "       Hal Lindon            1470                464            31.564626               256           17.414966                     87                 5.918367                     98                 6.666667                      254                  17.278912                   132                8.979592                   54               3.673469                        86                    5.850340\n",
      "Benzinga_Newsdesk            1239                 84             6.779661                42            3.389831                     18                 1.452785                   2131               171.993543                      117                   9.443099                    42                3.389831                   88               7.102502                        12                    0.968523\n"
     ]
    }
   ],
   "source": [
    "# Identify topic preferences by publisher\n",
    "topic_categories = topic_modeler.identify_topic_categories()\n",
    "topic_prefs = publisher_analyzer.identify_topic_preferences(topic_categories, top_n=10)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TOPIC PREFERENCES BY PUBLISHER\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Percentage of articles mentioning each topic category:\")\n",
    "print(topic_prefs.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize topic preferences\n",
    "publisher_analyzer.plot_topic_preferences(topic_categories, top_n=10, save=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SAVING RESULTS\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m80\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Descriptive statistics\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m stats_df = \u001b[43mpd\u001b[49m.DataFrame([stats[\u001b[33m'\u001b[39m\u001b[33mdescriptive\u001b[39m\u001b[33m'\u001b[39m]])\n\u001b[32m     14\u001b[39m stats_df.to_csv(output_dir / \u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33m\"\u001b[39m\u001b[33mdescriptive_statistics.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✓ Descriptive statistics saved\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "from pathlib import Path\n",
    "output_dir = Path(\"../output\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "(output_dir / \"data\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save all results\n",
    "print(\"=\" * 80)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Descriptive statistics\n",
    "stats_df = pd.DataFrame([stats['descriptive']])\n",
    "stats_df.to_csv(output_dir / \"data\" / \"descriptive_statistics.csv\", index=False)\n",
    "print(\"✓ Descriptive statistics saved\")\n",
    "\n",
    "# Top publishers\n",
    "top_publishers.to_csv(output_dir / \"data\" / \"top_publishers.csv\", index=False)\n",
    "print(\"✓ Top publishers saved\")\n",
    "\n",
    "# Keywords\n",
    "keywords_df.to_csv(output_dir / \"data\" / \"frequent_keywords.csv\", index=False)\n",
    "print(\"✓ Frequent keywords saved\")\n",
    "\n",
    "# LDA topics\n",
    "lda_topics_df = pd.DataFrame([\n",
    "    {'topic': k, 'words': ', '.join(v['top_words'])} \n",
    "    for k, v in lda_topics.items()\n",
    "])\n",
    "lda_topics_df.to_csv(output_dir / \"data\" / \"lda_topics.csv\", index=False)\n",
    "print(\"✓ LDA topics saved\")\n",
    "\n",
    "# Articles with topics\n",
    "df_with_topics.to_csv(output_dir / \"data\" / \"articles_with_topics.csv\", index=False)\n",
    "print(\"✓ Articles with topic assignments saved\")\n",
    "\n",
    "# Publisher rankings\n",
    "rankings.to_csv(output_dir / \"data\" / \"publisher_rankings.csv\", index=False)\n",
    "print(\"✓ Publisher rankings saved\")\n",
    "\n",
    "# Topic preferences\n",
    "topic_prefs.to_csv(output_dir / \"data\" / \"publisher_topic_preferences.csv\", index=False)\n",
    "print(\"✓ Publisher topic preferences saved\")\n",
    "\n",
    "# News spikes\n",
    "spikes.to_csv(output_dir / \"data\" / \"news_spikes.csv\", index=False)\n",
    "print(\"✓ News spikes saved\")\n",
    "\n",
    "# Summary report\n",
    "report = eda.generate_summary_report()\n",
    "with open(output_dir / \"eda_summary_report.txt\", 'w', encoding='utf-8') as f:\n",
    "    f.write(report)\n",
    "print(\"✓ Summary report saved\")\n",
    "\n",
    "print(f\"\\n✓ All results saved to: {output_dir.absolute()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary and Recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eda' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Generate and display summary report\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m report = \u001b[43meda\u001b[49m.generate_summary_report()\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(report)\n",
      "\u001b[31mNameError\u001b[39m: name 'eda' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate and display summary report\n",
    "report = eda.generate_summary_report()\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations for Next Steps\n",
    "\n",
    "**1. Sentiment Analysis Preparation:**\n",
    "- Use extracted topics to create topic-based sentiment features\n",
    "- Consider publisher-specific sentiment patterns\n",
    "- Analyze sentiment trends around news spikes\n",
    "- Create time-based sentiment features (hour, day of week)\n",
    "\n",
    "**2. Feature Engineering:**\n",
    "- Headline length and word count (already extracted)\n",
    "- Topic labels from LDA/BERTopic\n",
    "- Publisher credibility/weighting factors\n",
    "- Temporal features (time since market open, day of week)\n",
    "- Stock-specific news frequency\n",
    "\n",
    "**3. Correlation Analysis:**\n",
    "- Correlate sentiment scores with stock price movements\n",
    "- Analyze lag effects (news impact on next day/week prices)\n",
    "- Study publisher influence on market reactions\n",
    "- Identify which topics drive price movements\n",
    "\n",
    "**4. Model Preparation:**\n",
    "- Create train/validation/test splits respecting temporal order\n",
    "- Handle class imbalance if predicting price direction\n",
    "- Consider multi-class classification (up/down/neutral)\n",
    "- Feature selection based on correlation analysis\n",
    "\n",
    "**5. Sentiment Scoring Approaches:**\n",
    "- Use VADER (financial lexicon-aware)\n",
    "- Fine-tune BERT/RoBERTa on financial news\n",
    "- Create custom financial sentiment dictionary\n",
    "- Combine multiple sentiment scores\n",
    "\n",
    "**6. Validation Strategy:**\n",
    "- Time-series cross-validation\n",
    "- Walk-forward analysis\n",
    "- Out-of-sample testing on recent data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
